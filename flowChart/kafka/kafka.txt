Kafka

Kafka中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立，每个主题又可以分为一个或多个分区，
分区是kafka的最小并行操作单元，一个分区的数据只能同时被一个消费者消费，而分区数决定了消费者的并行度

每条消息在发送时会根据分区规则被追加到指定的分区中，分区中的每条消息都会被分配一个唯一的序列号，也就是偏移量（offset）

1、优先副本：
Kafka为了提高系统可扩展性，为消息存储进行了分区，为了保证可靠性，又采取了多副本冗余的策略
多副本冗余：同一个分区的数据副本会冗余多份，并保证均匀的分配在每一个broker上，为了保证每一份broker上只有一个数据副本，以防数据丢失
其中，只有一个broker上的副本可作为leader用于与外部做读写操作，叫做leader节点，而其他的只是leader副本的备份，
做同步而已，叫做follower节点

leader节点直接代表了此分区的负载，为了让kafka集群负载均衡：
优先副本策略：当一个broker节点已经作为某一个分区的leader节点，那么它就不会再分配为其他分区的leader节点，只可能为其他分区的follower节点
通过优先副本策略实现了不同分区的leader节点，均匀地分配在不同的broker节点上，从而达到了理论上的负载均衡（分区平衡）（前提是每个分区的负载都一样）

问题：分区的负载有大小，优先副本策略并不能完全保证kafka集群的负载均衡

保证分区平衡：Kafka内部提供了自动分区平衡选项，启动定时任务，计算所以broker节点的不平衡率：当非优先副本数/分区总数，超过一定阈值
但生产环境不建议使用，分区平衡过程会引起客户端阻塞，平衡时间也无法把控，必然会引起业务异常，建议人工手动进行控制



2、分区的重分配：
当broker宕机或新增broker时，broker节点与分区的映射关系会被重新分配，具体方式：每个分区在新的broker服务集群中各自新建一个副本，并与每个分区的leader节点进行数据同步，同步结束后，
删除原有副本

注意：重分配的本质在于数据复制，数据复制会占用资源，如果数据量太大会影响整体性能，在实际操作中，要减小分配力度，分成多个小批次来执行
如果流量十分巨大，减小分配力度不足以满足要求，可以采用限流复制流量保证整体服务的稳定

修改副本因子 = 分区的重分配

3、如何选择分区数
因素：业务场景（消息的有序性）、软件条件、硬件条件、负载情况
吞吐量与分区数的关系：
一般的，当分区数上升，吞吐量就会增大，当分区数达到一定的阈值，吞吐量就会进入瓶颈，甚至下降
此时就要从别的因素入手如：磁盘大小、文件系统、IO调度等
分区数越多，对集群的影响也就越多，比如：冗余副本过多造成的分区重分配时间过长，日志文件过大等


日志存储
不考虑多副本情况下，一个分区对一个日志，为了防止日志文件过大，又引入了日志分段的概念，将Log切分为多个LogSegment，方便维护与清理
Log中追加的消息是顺序写入的，所以只有最后一个LogSegement才能执行写入操作，又被称为"activeSegment"，随着"activeSegment"不断增大，
又会对其进行拆分，创建新的"activeSegment"



